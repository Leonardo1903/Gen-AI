{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0045d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9d281f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"HF_TOKEN\"] = os.getenv(\"HF_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52066c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"google/gemma-3-1b-it\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945f0612",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db8a296",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0442eac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokenizer(\"Hello, how are you?\"))\n",
    "print(tokenizer.get_vocab())\n",
    "\n",
    "input_tokens = tokenizer(\"Hello, how are you?\")[\"input_ids\"]\n",
    "print(input_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ffbbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2999e504",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.bfloat16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d80d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "gen_pipeline = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0abde1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_pipeline(\"Hey there\", max_new_tokens=25)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
